T4cbd4cb6f3a79d016d918245cc4f6fbf	own_claim 332 377	We use the automated calibration technique in
T1e3b976abdeeda9d2acb7cef08bddd08	data 380 402	White and Forsyth 2005
Tdc805218f19f56ebe340d564d26085d4	own_claim 409 443	any standard calibration will work
T634141f73145e772d56b2336ddf3af7d	data 446 456	Zhang 2002
Tc08fe3c6984d7d2a9d0180e21841d3de	data 463 475	Bouguet 2005
T3574b72e383f84e3021df000566114c1	own_claim 478 494	are good choices
T0e49f8bf468a1b8d1011628ddd746bd4	own_claim 588 617	Adequate lighting is critical
Ta54d4877d210ba8fde550723c4055b1f	own_claim 619 671	from our experience fewer lights degrade performance
T4350517a67308019580fda2def14ddf6	data 679 692	harsh shadows
T423d963437af78384fb82496fb1fb040	data 697 758	dim lighting causes motion blur through slower shutter speeds
Tf8f82f98a2ea223fa4eb77fa4038cfe6	own_claim 1084 1146	Our capture results are best evaluated by looking at our video
T3982d015a2c16c42c45fc2cabef740a9	own_claim 1177 1309	to compare against other capture techniques, it is also necessary to evaluate on several numerical criteria for each capture session
T49f33cc4eaf496a1cff521d5681637ed	own_claim 1599 1627	The sleeve example is unique
Tbb406fd969193c39994bad981262ce8b	data 1636 1677	it was one of the first items we captured
T3f925310f407f390a69cd9f89e42055d	own_claim 1679 1742	Much of the cloth is in contact with the floor and unobservable
T420aa512cddb17596ac23fb1ddc484e4	own_claim 1745 1774	yielding fewer bits of strain
T3f5a25f3cc92987b6ffe42d0237cebe5	own_claim 1789 1881	the camera images were not output in a linear color space, reducing the number of color bits
Tf2f779a15bcf3e181fcc0616105d62d1	own_claim 1949 1999	Our pants animation is by far the most challenging
Tb8d60220f037810098d74e1919274061	own_claim 2005 2057	we analyze some of the details a little more closely
Tad58f6f8c57254a074346ff260b7097a	own_claim 2059 2140	With an average of 2405 observed markers, there were 979 3D markers per megapixel
T67df1511fc0d33fc4a1a07d88504f24b	data 2145 2188	we factor out the pixels lost to background
T30cadcd31b94139dfce53dabdf6187d8	own_claim 2190 2286	we get 3500 3D markers per foreground megapixel or 282 foreground pixels per recovered 3D marker
T1eec272bce501e6561250bba37dcd61a	own_claim 2288 2350	Our marker observations average 56 pixels per marker per image
T6f06ff2c66c030e1d0468168d1843c14	own_claim 2352 2397	There are several reasons for the discrepancy
T6331b6754debae59d0151ea0facfc1ca	data 2399 2438	markers must be observed multiple times
Td90c85a6cef4dadc9006369f9b7bdaa9	data 2440 2496	approx 44% of 3D markers are observed in 3 or more views
T33cab6e64e36a40a2662c7064ca53971	own_claim 2499 2546	some markers are observed but not reconstructed
Td5a6cb3652471cd06d562936ba8a4ce5	data 2565 2587	missing correspondence
Tabe7b0032164d83f91dceb8d1aa6b709	own_claim 2594 2641	many pixels are not considered part of a marker
Ta351656c416ca6df075d6621de84ad9b	data 2643 2667;2713 2751	they lie in heavy shadow or occupy the edge between two markers
T6280e5639d8b431d433a158a9948f3cd	own_claim 2976 3031	This approach covers a reasonably large range of motion
Tec2057e91731a5a0d9eaf92a48a0529d	own_claim 3037 3059	ignores cloth dynamics
T75984dac5de69f0f7af6fcd860c3f8c2	own_claim 3061 3153	The largest challenge is that captured cloth meshes contain only points on the cloth surface
Tf734b3fbc144cfda38f60ce196c2dace	own_claim 3158 3188	we do not know joint locations
T27ca34e57da6308ded05daca65fea78e	own_claim 3199 3273	we insert proxy points for knee and hip joints in each of our basis meshes
T2aceb301e42dbd5f88cf7a54ddfb50b5	own_claim 3595 3686	Using our MATLAB implementation of MeshIK, this process takes around 5-10 seconds per frame
T2c9e85c8e797e2005bad482eea15c86f	data 3765 3823	a small basis to adequately express a full range of motion
T0486358d4a6d67aad96d667ab031a7ff	own_claim 3825 3873	each basis pose must be an extreme configuration
Tfba8d8806b918598e8e4b7f61b2dfbab	own_claim 3875 3893	For simple objects
T25ccac91236686a776e15f9873caac95	data 3902 3912	a cylinder
T9e0ce0e9396a85a10ea02acde4e3fa6a	own_claim 3914 3926	a small bend
T27e8540e5030b53f333f6d4510b0edef	own_claim 3941 3986	is sufficient to extrapolate to a larger bend
T288050ef8f10f78150ca0ce00fdb85c5	data 3989 4007	Sumner et al. 2005
T3d657f6bda24eda30b93e8cd9307097e	own_claim 4019 4061	for pants the relationship is more complex
T8e57fa42bdce9dff3e7d36058ec01c3e	data 4063 4170	the fact that no folding occurs in a small bend does not imply that folding will be absent in a larger bend
T23851be913daea406c81de2f0ae911d8	data 4187 4236	a decent amount of folding occurs in a small bend
Tb799167d09918f8b9d9e11ccedb98338	own_claim 4238 4299	we do not expect extreme folds in a corresponding larger bend
T9d01ee0f7e775d4c4d656ba848584958	own_claim 4314 4335	MeshIK is most useful
T9e51e11f7fcf7fc571d34e9e4e9abf27	data 4341 4403	a basis is carefully chosen to prevent extrapolation artifacts
T9263a61a156699833a507d4c4b1c0553	own_claim 4405 4475	One drawback to our approach is the loss of secondary kinematic motion
Tbbe1c9128d5c465f8789a65ebcc5e899	data 4485 4508	the sway of loose cloth
T66fba6ca7bb4b670f207dc17f73c9514	data 4518 4558	MeshIK does not use velocity information
Tc26969116ffdc009a953c192876e5267	own_claim 4560 4598	the resulting animation appears damped

